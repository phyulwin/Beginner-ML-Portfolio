{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486dd478-f8c8-42a3-879c-ab39b8392b5b",
   "metadata": {},
   "source": [
    "# Image Classification using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbea37e-0026-4e3b-937a-909a70556395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install: pip3 install torch torchvision matplotlib\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor # turn image data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b10d093-8500-45b4-9d73-dc6f798f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17677e3-74c1-4991-b3bb-f6e30743969a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefe7420-af61-4503-a9ee-c4411d47a5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb81af5-f15c-4f11-8f2c-f809d3e07805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data # gives you data with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08851a70-9c0e-4a6f-b297-ec39a38ad3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape # grayscale in one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731b068c-4a95-4fef-ba02-b826a87c10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size() # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac136d7-56e9-4b9e-8794-7ee35a2f9767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeead1d3-b2a4-4ffa-b9d6-562715f99fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a6b7bb-b5f5-4b3a-bb82-b7bf18af3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b831991-fc8d-4fdb-b397-d7154c8541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size = 100, shuffle=True, num_workers=1),\n",
    "    'test': DataLoader(test_data, batch_size = 100, shuffle=True, num_workers=1),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd465c37-d915-4329-82c9-34175645cbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1a886acf500>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1a886a73dd0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3443e1f-dd2a-401f-9c41-4682c8a6878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim # optimizer\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=5) # 1 channel in, 10 channel out\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d() # dropout regularization layer based on probability where some nodes are deactivated\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(320, 50) # dense layer\n",
    "        self.fc2 = nn.Linear(50, 10) \n",
    "\n",
    "    # defines the forward pass of the network, which is how the input data x is processed through the layers of the network\n",
    "    def forward(self, x): \n",
    "        # ReLU - rectified linear unit activation function for model linearity\n",
    "        # F.relu(...): Applies the ReLU activation function to the output\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) \n",
    "        # F.max_pool2d(..., 2): Applies a 2D max pooling operation with a kernel size of 2\n",
    "        x = x.view(-1, 320) # 320 = 20 x 4 x 4: reshape x to have 320 features\n",
    "        x = F.relu(self.fc1(x)) # Apply a fully connected layer and ReLU activation\n",
    "        x = F.dropout(x, training=self.training) # Apply dropout to prevent overfitting.\n",
    "        x = self.fc2(x) # Apply another fully connected layer.\n",
    "        # Convert the output to probabilities.\n",
    "        return F.softmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ec239-bbf0-48e3-88ef-ade2a0b355bb",
   "metadata": {},
   "source": [
    "### Fully Connected Layer: This layer connects every neuron in the previous layer to every neuron in the next layer.\n",
    "### ReLU Activation: Introduces non-linearity to the model and helps the neural network learn more complex functions and improves its ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d1b707b-ffe6-4e06-9e22-4eb3f95c6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The Adam optimizer is a popular optimization algorithm used in training deep learning models. It stands for Adaptive Moment Estimation.\n",
    "###### Uses moving averages of the gradients and the squared gradients to provide a smoother and more stable update process.\n",
    "###### Adjusts the learning rate for each parameter individually, which helps in faster convergence and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eec4ead-4b01-42e4-ad41-e255d21d3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following process needs to be done manually in Torch; not in Keras\n",
    "import torch\n",
    "\n",
    "# optimize the performance of neural network training and inference\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Creates an instance of the CNN model and moves it to the specified device (GPU or CPU)\n",
    "model = CNN().to(device)\n",
    "# Initializes the Adam optimizer with the model's parameters and a learning rate of 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Defines the loss function as cross-entropy loss, commonly used for classification tasks.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch): \n",
    "    model.train() # put model in training mode\n",
    "    for batch_index, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # set the gradient of each batch to zero \n",
    "        output = model(data) # Passes the input data through the model to get the output predictions.\n",
    "        loss = loss_fn(output, target) # Calculates the loss between the model's predictions and the actual target values. \n",
    "        loss.backward() # Computes the gradients of the loss with respect to the model's parameters (weights) for backpropagation.\n",
    "        optimizer.step() # Updates the model's parameters using the computed gradients to minimize the loss.\n",
    "\n",
    "        '''\n",
    "        # Checks if batch_index is a multiple of 20. \n",
    "        # If it is, it prints the current training epoch, the progress of the batches processed, and the current loss value.\n",
    "        if batch_index % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(loaders[\"train\"].dataset)}'\n",
    "      f' ({100. * batch_index / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}') '''\n",
    "\n",
    "        # Every 20 batches, print the training progress\n",
    "        if batch_index % 20 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_index}, Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e458194-e495-49f0-bb9f-688f9e732b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            # finds the index of the maximum value in the output tensor along the specified dimension\n",
    "            prediction = output.argmax(dim=1, keepdim=True) # ensures that the output tensor retains the same number of dimensions as the input\n",
    "            # compares the predicted classes with the actual target and counts the number of correct predictions and adds this count to the cumulative\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    average_loss = test_loss\n",
    "    total_samples = len(loaders['test'].dataset)\n",
    "    accuracy = 100. * correct / total_samples\n",
    "    \n",
    "    print(f'Test Set: Average Loss: {average_loss:.4f}, Accuracy: {correct}/{total_samples} ({accuracy:.0f}%)')                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc560d54-a0ea-4b59-8660-365bac8c248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Batch normalization is a technique used in training deep neural networks to improve their performance and stability.\n",
    "###### It normalizes the input of each layer so that they have a mean of 0 and a standard deviation of 1. \n",
    "###### This helps in stabilizing the learning process. After normalization, it scales and shifts the data using learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9632f3b-3b17-403c-bd0c-a9dd559a7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\646ca\\AppData\\Local\\Temp\\ipykernel_27608\\761587904.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 1.538422\n",
      "Epoch: 1, Batch: 20, Loss: 1.651673\n",
      "Epoch: 1, Batch: 40, Loss: 1.582036\n",
      "Epoch: 1, Batch: 60, Loss: 1.578352\n",
      "Epoch: 1, Batch: 80, Loss: 1.561228\n",
      "Epoch: 1, Batch: 100, Loss: 1.612728\n",
      "Epoch: 1, Batch: 120, Loss: 1.625250\n",
      "Epoch: 1, Batch: 140, Loss: 1.586293\n",
      "Epoch: 1, Batch: 160, Loss: 1.597601\n",
      "Epoch: 1, Batch: 180, Loss: 1.553201\n",
      "Epoch: 1, Batch: 200, Loss: 1.560512\n",
      "Epoch: 1, Batch: 220, Loss: 1.616825\n",
      "Epoch: 1, Batch: 240, Loss: 1.594082\n",
      "Epoch: 1, Batch: 260, Loss: 1.571241\n",
      "Epoch: 1, Batch: 280, Loss: 1.567431\n",
      "Epoch: 1, Batch: 300, Loss: 1.576642\n",
      "Epoch: 1, Batch: 320, Loss: 1.550215\n",
      "Epoch: 1, Batch: 340, Loss: 1.569501\n",
      "Epoch: 1, Batch: 360, Loss: 1.595542\n",
      "Epoch: 1, Batch: 380, Loss: 1.591128\n",
      "Epoch: 1, Batch: 400, Loss: 1.588434\n",
      "Epoch: 1, Batch: 420, Loss: 1.574360\n",
      "Epoch: 1, Batch: 440, Loss: 1.562705\n",
      "Epoch: 1, Batch: 460, Loss: 1.563896\n",
      "Epoch: 1, Batch: 480, Loss: 1.590219\n",
      "Epoch: 1, Batch: 500, Loss: 1.557410\n",
      "Epoch: 1, Batch: 520, Loss: 1.600300\n",
      "Epoch: 1, Batch: 540, Loss: 1.581901\n",
      "Epoch: 1, Batch: 560, Loss: 1.557459\n",
      "Epoch: 1, Batch: 580, Loss: 1.547261\n",
      "Test Set: Average Loss: 0.0151, Accuracy: 9561/10000 (96%)\n",
      "Epoch: 2, Batch: 0, Loss: 1.537018\n",
      "Epoch: 2, Batch: 20, Loss: 1.592253\n",
      "Epoch: 2, Batch: 40, Loss: 1.556202\n",
      "Epoch: 2, Batch: 60, Loss: 1.615089\n",
      "Epoch: 2, Batch: 80, Loss: 1.531403\n",
      "Epoch: 2, Batch: 100, Loss: 1.575711\n",
      "Epoch: 2, Batch: 120, Loss: 1.549675\n",
      "Epoch: 2, Batch: 140, Loss: 1.553179\n",
      "Epoch: 2, Batch: 160, Loss: 1.566883\n",
      "Epoch: 2, Batch: 180, Loss: 1.551759\n",
      "Epoch: 2, Batch: 200, Loss: 1.511981\n",
      "Epoch: 2, Batch: 220, Loss: 1.567190\n",
      "Epoch: 2, Batch: 240, Loss: 1.570736\n",
      "Epoch: 2, Batch: 260, Loss: 1.534340\n",
      "Epoch: 2, Batch: 280, Loss: 1.537889\n",
      "Epoch: 2, Batch: 300, Loss: 1.531100\n",
      "Epoch: 2, Batch: 320, Loss: 1.545790\n",
      "Epoch: 2, Batch: 340, Loss: 1.614709\n",
      "Epoch: 2, Batch: 360, Loss: 1.503414\n",
      "Epoch: 2, Batch: 380, Loss: 1.600348\n",
      "Epoch: 2, Batch: 400, Loss: 1.510340\n",
      "Epoch: 2, Batch: 420, Loss: 1.546726\n",
      "Epoch: 2, Batch: 440, Loss: 1.552855\n",
      "Epoch: 2, Batch: 460, Loss: 1.566099\n",
      "Epoch: 2, Batch: 480, Loss: 1.580612\n",
      "Epoch: 2, Batch: 500, Loss: 1.564836\n",
      "Epoch: 2, Batch: 520, Loss: 1.621487\n",
      "Epoch: 2, Batch: 540, Loss: 1.587612\n",
      "Epoch: 2, Batch: 560, Loss: 1.563437\n",
      "Epoch: 2, Batch: 580, Loss: 1.536096\n",
      "Test Set: Average Loss: 0.0150, Accuracy: 9611/10000 (96%)\n",
      "Epoch: 3, Batch: 0, Loss: 1.531281\n",
      "Epoch: 3, Batch: 20, Loss: 1.527494\n",
      "Epoch: 3, Batch: 40, Loss: 1.516913\n",
      "Epoch: 3, Batch: 60, Loss: 1.531242\n",
      "Epoch: 3, Batch: 80, Loss: 1.533877\n",
      "Epoch: 3, Batch: 100, Loss: 1.537199\n",
      "Epoch: 3, Batch: 120, Loss: 1.532907\n",
      "Epoch: 3, Batch: 140, Loss: 1.578242\n",
      "Epoch: 3, Batch: 160, Loss: 1.551237\n",
      "Epoch: 3, Batch: 180, Loss: 1.604211\n",
      "Epoch: 3, Batch: 200, Loss: 1.556251\n",
      "Epoch: 3, Batch: 220, Loss: 1.513452\n",
      "Epoch: 3, Batch: 240, Loss: 1.577795\n",
      "Epoch: 3, Batch: 260, Loss: 1.555166\n",
      "Epoch: 3, Batch: 280, Loss: 1.540228\n",
      "Epoch: 3, Batch: 300, Loss: 1.555218\n",
      "Epoch: 3, Batch: 320, Loss: 1.530495\n",
      "Epoch: 3, Batch: 340, Loss: 1.559480\n",
      "Epoch: 3, Batch: 360, Loss: 1.559483\n",
      "Epoch: 3, Batch: 380, Loss: 1.542856\n",
      "Epoch: 3, Batch: 400, Loss: 1.609359\n",
      "Epoch: 3, Batch: 420, Loss: 1.543212\n",
      "Epoch: 3, Batch: 440, Loss: 1.568294\n",
      "Epoch: 3, Batch: 460, Loss: 1.570810\n",
      "Epoch: 3, Batch: 480, Loss: 1.531491\n",
      "Epoch: 3, Batch: 500, Loss: 1.500456\n",
      "Epoch: 3, Batch: 520, Loss: 1.532430\n",
      "Epoch: 3, Batch: 540, Loss: 1.526426\n",
      "Epoch: 3, Batch: 560, Loss: 1.595548\n",
      "Epoch: 3, Batch: 580, Loss: 1.506423\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9675/10000 (97%)\n",
      "Epoch: 4, Batch: 0, Loss: 1.537339\n",
      "Epoch: 4, Batch: 20, Loss: 1.487915\n",
      "Epoch: 4, Batch: 40, Loss: 1.510411\n",
      "Epoch: 4, Batch: 60, Loss: 1.575467\n",
      "Epoch: 4, Batch: 80, Loss: 1.502836\n",
      "Epoch: 4, Batch: 100, Loss: 1.530702\n",
      "Epoch: 4, Batch: 120, Loss: 1.531199\n",
      "Epoch: 4, Batch: 140, Loss: 1.585400\n",
      "Epoch: 4, Batch: 160, Loss: 1.500208\n",
      "Epoch: 4, Batch: 180, Loss: 1.496286\n",
      "Epoch: 4, Batch: 200, Loss: 1.586198\n",
      "Epoch: 4, Batch: 220, Loss: 1.544562\n",
      "Epoch: 4, Batch: 240, Loss: 1.535344\n",
      "Epoch: 4, Batch: 260, Loss: 1.574190\n",
      "Epoch: 4, Batch: 280, Loss: 1.543963\n",
      "Epoch: 4, Batch: 300, Loss: 1.502932\n",
      "Epoch: 4, Batch: 320, Loss: 1.539876\n",
      "Epoch: 4, Batch: 340, Loss: 1.534808\n",
      "Epoch: 4, Batch: 360, Loss: 1.508206\n",
      "Epoch: 4, Batch: 380, Loss: 1.517316\n",
      "Epoch: 4, Batch: 400, Loss: 1.530942\n",
      "Epoch: 4, Batch: 420, Loss: 1.522739\n",
      "Epoch: 4, Batch: 440, Loss: 1.537587\n",
      "Epoch: 4, Batch: 460, Loss: 1.510868\n",
      "Epoch: 4, Batch: 480, Loss: 1.521472\n",
      "Epoch: 4, Batch: 500, Loss: 1.553837\n",
      "Epoch: 4, Batch: 520, Loss: 1.566594\n",
      "Epoch: 4, Batch: 540, Loss: 1.549143\n",
      "Epoch: 4, Batch: 560, Loss: 1.545599\n",
      "Epoch: 4, Batch: 580, Loss: 1.528275\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9686/10000 (97%)\n",
      "Epoch: 5, Batch: 0, Loss: 1.566314\n",
      "Epoch: 5, Batch: 20, Loss: 1.544072\n",
      "Epoch: 5, Batch: 40, Loss: 1.513544\n",
      "Epoch: 5, Batch: 60, Loss: 1.510066\n",
      "Epoch: 5, Batch: 80, Loss: 1.540902\n",
      "Epoch: 5, Batch: 100, Loss: 1.502635\n",
      "Epoch: 5, Batch: 120, Loss: 1.504374\n",
      "Epoch: 5, Batch: 140, Loss: 1.556297\n",
      "Epoch: 5, Batch: 160, Loss: 1.532868\n",
      "Epoch: 5, Batch: 180, Loss: 1.537111\n",
      "Epoch: 5, Batch: 200, Loss: 1.566270\n",
      "Epoch: 5, Batch: 220, Loss: 1.534182\n",
      "Epoch: 5, Batch: 240, Loss: 1.533375\n",
      "Epoch: 5, Batch: 260, Loss: 1.519750\n",
      "Epoch: 5, Batch: 280, Loss: 1.530864\n",
      "Epoch: 5, Batch: 300, Loss: 1.531662\n",
      "Epoch: 5, Batch: 320, Loss: 1.520555\n",
      "Epoch: 5, Batch: 340, Loss: 1.546263\n",
      "Epoch: 5, Batch: 360, Loss: 1.543065\n",
      "Epoch: 5, Batch: 380, Loss: 1.538056\n",
      "Epoch: 5, Batch: 400, Loss: 1.567292\n",
      "Epoch: 5, Batch: 420, Loss: 1.542150\n",
      "Epoch: 5, Batch: 440, Loss: 1.522592\n",
      "Epoch: 5, Batch: 460, Loss: 1.506420\n",
      "Epoch: 5, Batch: 480, Loss: 1.541352\n",
      "Epoch: 5, Batch: 500, Loss: 1.525828\n",
      "Epoch: 5, Batch: 520, Loss: 1.527276\n",
      "Epoch: 5, Batch: 540, Loss: 1.573418\n",
      "Epoch: 5, Batch: 560, Loss: 1.557370\n",
      "Epoch: 5, Batch: 580, Loss: 1.527982\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9726/10000 (97%)\n",
      "Epoch: 6, Batch: 0, Loss: 1.516107\n",
      "Epoch: 6, Batch: 20, Loss: 1.512046\n",
      "Epoch: 6, Batch: 40, Loss: 1.532153\n",
      "Epoch: 6, Batch: 60, Loss: 1.491656\n",
      "Epoch: 6, Batch: 80, Loss: 1.494585\n",
      "Epoch: 6, Batch: 100, Loss: 1.585328\n",
      "Epoch: 6, Batch: 120, Loss: 1.526238\n",
      "Epoch: 6, Batch: 140, Loss: 1.573680\n",
      "Epoch: 6, Batch: 160, Loss: 1.540781\n",
      "Epoch: 6, Batch: 180, Loss: 1.544618\n",
      "Epoch: 6, Batch: 200, Loss: 1.545897\n",
      "Epoch: 6, Batch: 220, Loss: 1.510990\n",
      "Epoch: 6, Batch: 240, Loss: 1.512346\n",
      "Epoch: 6, Batch: 260, Loss: 1.562397\n",
      "Epoch: 6, Batch: 280, Loss: 1.512366\n",
      "Epoch: 6, Batch: 300, Loss: 1.542984\n",
      "Epoch: 6, Batch: 320, Loss: 1.526473\n",
      "Epoch: 6, Batch: 340, Loss: 1.545675\n",
      "Epoch: 6, Batch: 360, Loss: 1.540081\n",
      "Epoch: 6, Batch: 380, Loss: 1.518140\n",
      "Epoch: 6, Batch: 400, Loss: 1.560694\n",
      "Epoch: 6, Batch: 420, Loss: 1.537143\n",
      "Epoch: 6, Batch: 440, Loss: 1.537114\n",
      "Epoch: 6, Batch: 460, Loss: 1.499394\n",
      "Epoch: 6, Batch: 480, Loss: 1.528385\n",
      "Epoch: 6, Batch: 500, Loss: 1.536970\n",
      "Epoch: 6, Batch: 520, Loss: 1.539840\n",
      "Epoch: 6, Batch: 540, Loss: 1.525057\n",
      "Epoch: 6, Batch: 560, Loss: 1.536858\n",
      "Epoch: 6, Batch: 580, Loss: 1.486010\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9723/10000 (97%)\n",
      "Epoch: 7, Batch: 0, Loss: 1.534691\n",
      "Epoch: 7, Batch: 20, Loss: 1.535354\n",
      "Epoch: 7, Batch: 40, Loss: 1.530902\n",
      "Epoch: 7, Batch: 60, Loss: 1.541814\n",
      "Epoch: 7, Batch: 80, Loss: 1.552913\n",
      "Epoch: 7, Batch: 100, Loss: 1.518098\n",
      "Epoch: 7, Batch: 120, Loss: 1.542767\n",
      "Epoch: 7, Batch: 140, Loss: 1.491665\n",
      "Epoch: 7, Batch: 160, Loss: 1.539937\n",
      "Epoch: 7, Batch: 180, Loss: 1.551375\n",
      "Epoch: 7, Batch: 200, Loss: 1.507858\n",
      "Epoch: 7, Batch: 220, Loss: 1.548491\n",
      "Epoch: 7, Batch: 240, Loss: 1.533226\n",
      "Epoch: 7, Batch: 260, Loss: 1.512616\n",
      "Epoch: 7, Batch: 280, Loss: 1.598520\n",
      "Epoch: 7, Batch: 300, Loss: 1.515258\n",
      "Epoch: 7, Batch: 320, Loss: 1.528964\n",
      "Epoch: 7, Batch: 340, Loss: 1.525473\n",
      "Epoch: 7, Batch: 360, Loss: 1.576425\n",
      "Epoch: 7, Batch: 380, Loss: 1.573512\n",
      "Epoch: 7, Batch: 400, Loss: 1.500517\n",
      "Epoch: 7, Batch: 420, Loss: 1.528519\n",
      "Epoch: 7, Batch: 440, Loss: 1.561787\n",
      "Epoch: 7, Batch: 460, Loss: 1.505623\n",
      "Epoch: 7, Batch: 480, Loss: 1.496196\n",
      "Epoch: 7, Batch: 500, Loss: 1.516073\n",
      "Epoch: 7, Batch: 520, Loss: 1.541976\n",
      "Epoch: 7, Batch: 540, Loss: 1.583337\n",
      "Epoch: 7, Batch: 560, Loss: 1.555251\n",
      "Epoch: 7, Batch: 580, Loss: 1.514787\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9755/10000 (98%)\n",
      "Epoch: 8, Batch: 0, Loss: 1.521145\n",
      "Epoch: 8, Batch: 20, Loss: 1.550801\n",
      "Epoch: 8, Batch: 40, Loss: 1.556258\n",
      "Epoch: 8, Batch: 60, Loss: 1.530210\n",
      "Epoch: 8, Batch: 80, Loss: 1.536746\n",
      "Epoch: 8, Batch: 100, Loss: 1.541605\n",
      "Epoch: 8, Batch: 120, Loss: 1.531674\n",
      "Epoch: 8, Batch: 140, Loss: 1.490819\n",
      "Epoch: 8, Batch: 160, Loss: 1.511417\n",
      "Epoch: 8, Batch: 180, Loss: 1.551744\n",
      "Epoch: 8, Batch: 200, Loss: 1.504385\n",
      "Epoch: 8, Batch: 220, Loss: 1.552173\n",
      "Epoch: 8, Batch: 240, Loss: 1.510651\n",
      "Epoch: 8, Batch: 260, Loss: 1.502799\n",
      "Epoch: 8, Batch: 280, Loss: 1.473611\n",
      "Epoch: 8, Batch: 300, Loss: 1.496176\n",
      "Epoch: 8, Batch: 320, Loss: 1.499795\n",
      "Epoch: 8, Batch: 340, Loss: 1.538209\n",
      "Epoch: 8, Batch: 360, Loss: 1.498171\n",
      "Epoch: 8, Batch: 380, Loss: 1.518145\n",
      "Epoch: 8, Batch: 400, Loss: 1.528705\n",
      "Epoch: 8, Batch: 420, Loss: 1.536570\n",
      "Epoch: 8, Batch: 440, Loss: 1.481749\n",
      "Epoch: 8, Batch: 460, Loss: 1.483907\n",
      "Epoch: 8, Batch: 480, Loss: 1.557622\n",
      "Epoch: 8, Batch: 500, Loss: 1.515751\n",
      "Epoch: 8, Batch: 520, Loss: 1.496797\n",
      "Epoch: 8, Batch: 540, Loss: 1.520459\n",
      "Epoch: 8, Batch: 560, Loss: 1.517279\n",
      "Epoch: 8, Batch: 580, Loss: 1.498428\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9766/10000 (98%)\n",
      "Epoch: 9, Batch: 0, Loss: 1.513895\n",
      "Epoch: 9, Batch: 20, Loss: 1.535899\n",
      "Epoch: 9, Batch: 40, Loss: 1.504759\n",
      "Epoch: 9, Batch: 60, Loss: 1.514251\n",
      "Epoch: 9, Batch: 80, Loss: 1.556486\n",
      "Epoch: 9, Batch: 100, Loss: 1.516883\n",
      "Epoch: 9, Batch: 120, Loss: 1.518066\n",
      "Epoch: 9, Batch: 140, Loss: 1.530151\n",
      "Epoch: 9, Batch: 160, Loss: 1.568478\n",
      "Epoch: 9, Batch: 180, Loss: 1.499848\n",
      "Epoch: 9, Batch: 200, Loss: 1.521902\n",
      "Epoch: 9, Batch: 220, Loss: 1.511707\n",
      "Epoch: 9, Batch: 240, Loss: 1.518670\n",
      "Epoch: 9, Batch: 260, Loss: 1.511275\n",
      "Epoch: 9, Batch: 280, Loss: 1.477268\n",
      "Epoch: 9, Batch: 300, Loss: 1.512548\n",
      "Epoch: 9, Batch: 320, Loss: 1.530300\n",
      "Epoch: 9, Batch: 340, Loss: 1.493286\n",
      "Epoch: 9, Batch: 360, Loss: 1.525769\n",
      "Epoch: 9, Batch: 380, Loss: 1.514020\n",
      "Epoch: 9, Batch: 400, Loss: 1.528813\n",
      "Epoch: 9, Batch: 420, Loss: 1.520106\n",
      "Epoch: 9, Batch: 440, Loss: 1.502078\n",
      "Epoch: 9, Batch: 460, Loss: 1.493749\n",
      "Epoch: 9, Batch: 480, Loss: 1.520767\n",
      "Epoch: 9, Batch: 500, Loss: 1.534227\n",
      "Epoch: 9, Batch: 520, Loss: 1.505251\n",
      "Epoch: 9, Batch: 540, Loss: 1.506403\n",
      "Epoch: 9, Batch: 560, Loss: 1.511995\n",
      "Epoch: 9, Batch: 580, Loss: 1.522315\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9786/10000 (98%)\n",
      "Epoch: 10, Batch: 0, Loss: 1.520294\n",
      "Epoch: 10, Batch: 20, Loss: 1.535609\n",
      "Epoch: 10, Batch: 40, Loss: 1.578003\n",
      "Epoch: 10, Batch: 60, Loss: 1.525899\n",
      "Epoch: 10, Batch: 80, Loss: 1.542132\n",
      "Epoch: 10, Batch: 100, Loss: 1.522812\n",
      "Epoch: 10, Batch: 120, Loss: 1.483241\n",
      "Epoch: 10, Batch: 140, Loss: 1.482114\n",
      "Epoch: 10, Batch: 160, Loss: 1.498142\n",
      "Epoch: 10, Batch: 180, Loss: 1.516700\n",
      "Epoch: 10, Batch: 200, Loss: 1.467350\n",
      "Epoch: 10, Batch: 220, Loss: 1.552074\n",
      "Epoch: 10, Batch: 240, Loss: 1.505124\n",
      "Epoch: 10, Batch: 260, Loss: 1.524279\n",
      "Epoch: 10, Batch: 280, Loss: 1.489388\n",
      "Epoch: 10, Batch: 300, Loss: 1.497856\n",
      "Epoch: 10, Batch: 320, Loss: 1.521119\n",
      "Epoch: 10, Batch: 340, Loss: 1.517149\n",
      "Epoch: 10, Batch: 360, Loss: 1.490116\n",
      "Epoch: 10, Batch: 380, Loss: 1.500478\n",
      "Epoch: 10, Batch: 400, Loss: 1.511039\n",
      "Epoch: 10, Batch: 420, Loss: 1.508639\n",
      "Epoch: 10, Batch: 440, Loss: 1.551419\n",
      "Epoch: 10, Batch: 460, Loss: 1.537385\n",
      "Epoch: 10, Batch: 480, Loss: 1.490597\n",
      "Epoch: 10, Batch: 500, Loss: 1.483326\n",
      "Epoch: 10, Batch: 520, Loss: 1.523650\n",
      "Epoch: 10, Batch: 540, Loss: 1.522485\n",
      "Epoch: 10, Batch: 560, Loss: 1.489439\n",
      "Epoch: 10, Batch: 580, Loss: 1.502292\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9798/10000 (98%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11): \n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8991b453-c796-40da-9783-051756696151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5e2d9b4-2f0f-449c-8186-a8662fe5f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8edd46f8-0f8c-4ab7-9f29-4e771c95bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\646ca\\AppData\\Local\\Temp\\ipykernel_27608\\761587904.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG4VJREFUeJzt3X9sVfX9x/FXC/SC0t6ulva2UmpBBSM/FhnUBmVudLR1Y6L84a9kZXEw3YWJndN0URG3pZMlatw6TBZHNRF1JAJRMzKstsStYEBJQzYb2nUWQ1smG/eWIgXbz/cP4v16pYDncm/fvZfnIzkJvfe+e98eb3hy29vbNOecEwAAIyzdegEAwMWJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNjrRf4sqGhIR06dEiZmZlKS0uzXgcA4JFzTn19fSosLFR6+tmf54y6AB06dEhFRUXWawAALtDBgwc1efLks14/6r4El5mZab0CACAOzvf3ecICVF9fryuuuELjx49XaWmp3nvvva80x5fdACA1nO/v84QE6NVXX1VNTY3Wrl2r999/X3PmzFFFRYUOHz6ciLsDACQjlwDz5893wWAw8vHg4KArLCx0dXV1550NhUJOEgcHBwdHkh+hUOicf9/H/RnQyZMntXfvXpWXl0cuS09PV3l5uVpaWs64/cDAgMLhcNQBAEh9cQ/QJ598osHBQeXn50ddnp+fr56enjNuX1dXJ7/fHzl4BRwAXBzMXwVXW1urUCgUOQ4ePGi9EgBgBMT954Byc3M1ZswY9fb2Rl3e29urQCBwxu19Pp98Pl+81wAAjHJxfwaUkZGhuXPnqrGxMXLZ0NCQGhsbVVZWFu+7AwAkqYS8E0JNTY2qq6v1jW98Q/Pnz9czzzyj/v5+/fCHP0zE3QEAklBCAnT77bfrP//5jx577DH19PTo61//urZv337GCxMAABevNOecs17ii8LhsPx+v/UaAIALFAqFlJWVddbrzV8FBwC4OBEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNxD9Djjz+utLS0qGPGjBnxvhsAQJIbm4hPeu211+qtt976/zsZm5C7AQAksYSUYezYsQoEAon41ACAFJGQ7wEdOHBAhYWFmjp1qu6++251dXWd9bYDAwMKh8NRBwAg9cU9QKWlpWpoaND27du1YcMGdXZ26sYbb1RfX9+wt6+rq5Pf748cRUVF8V4JADAKpTnnXCLv4OjRoyouLtZTTz2le+6554zrBwYGNDAwEPk4HA4TIQBIAaFQSFlZWWe9PuGvDsjOztbVV1+t9vb2Ya/3+Xzy+XyJXgMAMMok/OeAjh07po6ODhUUFCT6rgAASSTuAXrwwQfV3Nysf//73/r73/+uW2+9VWPGjNGdd94Z77sCACSxuH8J7uOPP9add96pI0eOaNKkSbrhhhu0a9cuTZo0Kd53BQBIYgl/EYJX4XBYfr/feg1g1CkuLvY8s3r16pjua968eZ5ngsGg55n9+/d7nkHyON+LEHgvOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMJ/IR2Q6q6++mrPM6tWrfI884Mf/MDzzLneCDLe/vKXv3ieWbJkieeZWH5j8kcffeR5RpJaW1tjmsNXwzMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmEhzzjnrJb4oHA7L7/dbr4Ekl54e27+trrnmGs8zO3bs8DwTCAQ8z6Sivr4+zzOZmZmeZ1paWjzPSNKNN97oeWZoaCim+0pFoVDonO/IzjMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEWOsFgPOZNGmS55nVq1fHdF+PPPJITHMjIRQKeZ6J5Y07pdjfzNWrWPfzasaMGTHNxXIeeDPSr45nQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACd6MFKPer3/9a88zP/rRjxKwyfBOnTrleeb+++/3PNPZ2el5Zu3atZ5nJOn666+PaW4kfPLJJ55nvv/978d0X5999llMc/hqeAYEADBBgAAAJjwHaOfOnVqyZIkKCwuVlpamrVu3Rl3vnNNjjz2mgoICTZgwQeXl5Tpw4EC89gUApAjPAerv79ecOXNUX18/7PXr16/Xs88+q+eee067d+/WpZdeqoqKCp04ceKClwUApA7PL0KoqqpSVVXVsNc55/TMM8/okUce0S233CJJevHFF5Wfn6+tW7fqjjvuuLBtAQApI67fA+rs7FRPT4/Ky8sjl/n9fpWWlqqlpWXYmYGBAYXD4agDAJD64hqgnp4eSVJ+fn7U5fn5+ZHrvqyurk5+vz9yFBUVxXMlAMAoZf4quNraWoVCochx8OBB65UAACMgrgEKBAKSpN7e3qjLe3t7I9d9mc/nU1ZWVtQBAEh9cQ1QSUmJAoGAGhsbI5eFw2Ht3r1bZWVl8bwrAECS8/wquGPHjqm9vT3ycWdnp/bt26ecnBxNmTJFa9as0a9+9StdddVVKikp0aOPPqrCwkItXbo0nnsDAJKc5wDt2bNH3/rWtyIf19TUSJKqq6vV0NCghx56SP39/Vq5cqWOHj2qG264Qdu3b9f48ePjtzUAIOmlOeec9RJfFA6H5ff7rdfAV5Ce7v0ruJs3b/Y88/nPlI2E1tZWzzMrVqzwPPOd73zH80x1dbXnmenTp3ueGe3++te/ep6prKxMwCY4n1AodM7v65u/Cg4AcHEiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACc+/jgH43E9/+lPPM7feemsCNjlTW1tbTHNPPvmk55l3333X84zP5/M8k4oOHDjgeebHP/5xAjaBBZ4BAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm0pxzznqJLwqHw/L7/dZrXFTGjRsX01xXV5fnmfz8/JjuK9X897//9Tzz+9//3vPMokWLPM9I0oIFC2Ka86q2ttbzTCxvGAsboVBIWVlZZ72eZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImx1gvA3tDQUExz//rXvzzPjNSbkX766acxzQ0MDHieqa+v9zzz1FNPeZ4pKiryPPPwww97nonV7t27Pc9s2LAhAZsgWfAMCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwZuRQoODgzHNffe73/U8873vfc/zzGeffeZ5Zt++fZ5nJOnDDz+Mac6riRMnep5Zu3at5xmfz+d5RpKOHTvmeaa6utrzTDgc9jyD1MEzIACACQIEADDhOUA7d+7UkiVLVFhYqLS0NG3dujXq+uXLlystLS3qqKysjNe+AIAU4TlA/f39mjNnzjl/CVdlZaW6u7sjx8svv3xBSwIAUo/nFyFUVVWpqqrqnLfx+XwKBAIxLwUASH0J+R5QU1OT8vLyNH36dN133306cuTIWW87MDCgcDgcdQAAUl/cA1RZWakXX3xRjY2NevLJJ9Xc3KyqqqqzvtS3rq5Ofr8/csTye+8BAMkn7j8HdMcdd0T+PGvWLM2ePVvTpk1TU1OTFi1adMbta2trVVNTE/k4HA4TIQC4CCT8ZdhTp05Vbm6u2tvbh73e5/MpKysr6gAApL6EB+jjjz/WkSNHVFBQkOi7AgAkEc9fgjt27FjUs5nOzk7t27dPOTk5ysnJ0bp167Rs2TIFAgF1dHTooYce0pVXXqmKioq4Lg4ASG6eA7Rnzx5961vfinz8+fdvqqurtWHDBrW2tuqFF17Q0aNHVVhYqMWLF+uXv/xlzO9JBQBITWnOOWe9xBeFw2H5/X7rNYCEiuWNOzdu3JiATYb3/PPPe55ZsWJFAjZBMguFQuf8vj7vBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATvBs2cIFycnI8zzQ1NXmemTlzpueZgwcPep6RpKuuusrzzMmTJ2O6L6Qu3g0bADAqESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmxlovACS7119/3fNMLG8sGosnnngipjneWBQjgWdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJ3owU+IKpU6d6npk1a1YCNjnTm2++6XmmoaEh/osAccIzIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABG9GipR0+eWXxzTX2NjoeWbixImeZw4ePOh5JhgMep4ZHBz0PAOMFJ4BAQBMECAAgAlPAaqrq9O8efOUmZmpvLw8LV26VG1tbVG3OXHihILBoC677DJNnDhRy5YtU29vb1yXBgAkP08Bam5uVjAY1K5du7Rjxw6dOnVKixcvVn9/f+Q2DzzwgF5//XVt3rxZzc3NOnTokG677ba4Lw4ASG6eXoSwffv2qI8bGhqUl5envXv3auHChQqFQnr++ee1adMmffvb35Ykbdy4Uddcc4127dql66+/Pn6bAwCS2gV9DygUCkmScnJyJEl79+7VqVOnVF5eHrnNjBkzNGXKFLW0tAz7OQYGBhQOh6MOAEDqizlAQ0NDWrNmjRYsWKCZM2dKknp6epSRkaHs7Oyo2+bn56unp2fYz1NXVye/3x85ioqKYl0JAJBEYg5QMBjU/v379corr1zQArW1tQqFQpEjlp+PAAAkn5h+EHXVqlV64403tHPnTk2ePDlyeSAQ0MmTJ3X06NGoZ0G9vb0KBALDfi6fzyefzxfLGgCAJObpGZBzTqtWrdKWLVv09ttvq6SkJOr6uXPnaty4cVE/Td7W1qauri6VlZXFZ2MAQErw9AwoGAxq06ZN2rZtmzIzMyPf1/H7/ZowYYL8fr/uuece1dTUKCcnR1lZWVq9erXKysp4BRwAIIqnAG3YsEGSdNNNN0VdvnHjRi1fvlyS9PTTTys9PV3Lli3TwMCAKioq9Ic//CEuywIAUoenADnnznub8ePHq76+XvX19TEvBVyo6667Lqa54uJizzNpaWmeZ/70pz95nunq6vI8A4xmvBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMT0G1GBkTR//nzPMy+88EICNhnewMCA55k333wzAZsAyYVnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACd6MFCPq0ksv9Tyzbt06zzPZ2dmeZ2L1v//9z/PMsWPHErAJkFx4BgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmODNSDGiVq5c6XmmoqIiAZsMr6enx/PMzTff7Hnmww8/9DwDpBqeAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJngzUoyowcFBzzOhUMjzzNNPP+15RpL++Mc/ep7p7u6O6b6Aix3PgAAAJggQAMCEpwDV1dVp3rx5yszMVF5enpYuXaq2trao29x0001KS0uLOu699964Lg0ASH6eAtTc3KxgMKhdu3Zpx44dOnXqlBYvXqz+/v6o261YsULd3d2RY/369XFdGgCQ/Dy9CGH79u1RHzc0NCgvL0979+7VwoULI5dfcsklCgQC8dkQAJCSLuh7QJ+/OiknJyfq8pdeekm5ubmaOXOmamtrdfz48bN+joGBAYXD4agDAJD6Yn4Z9tDQkNasWaMFCxZo5syZkcvvuusuFRcXq7CwUK2trXr44YfV1tam1157bdjPU1dXp3Xr1sW6BgAgScUcoGAwqP379+vdd9+NunzlypWRP8+aNUsFBQVatGiROjo6NG3atDM+T21trWpqaiIfh8NhFRUVxboWACBJxBSgVatW6Y033tDOnTs1efLkc962tLRUktTe3j5sgHw+n3w+XyxrAACSmKcAOee0evVqbdmyRU1NTSopKTnvzL59+yRJBQUFMS0IAEhNngIUDAa1adMmbdu2TZmZmerp6ZEk+f1+TZgwQR0dHdq0aZNuvvlmXXbZZWptbdUDDzyghQsXavbs2Qn5DwAAJCdPAdqwYYOk0z9s+kUbN27U8uXLlZGRobfeekvPPPOM+vv7VVRUpGXLlumRRx6J28IAgNTg+Utw51JUVKTm5uYLWggAcHFIc+eryggLh8Py+/3WawAALlAoFFJWVtZZr+fNSAEAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAx6gLknLNeAQAQB+f7+3zUBaivr896BQBAHJzv7/M0N8qecgwNDenQoUPKzMxUWlpa1HXhcFhFRUU6ePCgsrKyjDa0x3k4jfNwGufhNM7DaaPhPDjn1NfXp8LCQqWnn/15ztgR3OkrSU9P1+TJk895m6ysrIv6AfY5zsNpnIfTOA+ncR5Osz4Pfr//vLcZdV+CAwBcHAgQAMBEUgXI5/Np7dq18vl81quY4jycxnk4jfNwGufhtGQ6D6PuRQgAgItDUj0DAgCkDgIEADBBgAAAJggQAMBE0gSovr5eV1xxhcaPH6/S0lK999571iuNuMcff1xpaWlRx4wZM6zXSridO3dqyZIlKiwsVFpamrZu3Rp1vXNOjz32mAoKCjRhwgSVl5frwIEDNssm0PnOw/Lly894fFRWVtosmyB1dXWaN2+eMjMzlZeXp6VLl6qtrS3qNidOnFAwGNRll12miRMnatmyZert7TXaODG+ynm46aabzng83HvvvUYbDy8pAvTqq6+qpqZGa9eu1fvvv685c+aooqJChw8ftl5txF177bXq7u6OHO+++671SgnX39+vOXPmqL6+ftjr169fr2effVbPPfecdu/erUsvvVQVFRU6ceLECG+aWOc7D5JUWVkZ9fh4+eWXR3DDxGtublYwGNSuXbu0Y8cOnTp1SosXL1Z/f3/kNg888IBef/11bd68Wc3NzTp06JBuu+02w63j76ucB0lasWJF1ONh/fr1RhufhUsC8+fPd8FgMPLx4OCgKywsdHV1dYZbjby1a9e6OXPmWK9hSpLbsmVL5OOhoSEXCATcb3/728hlR48edT6fz7388ssGG46ML58H55yrrq52t9xyi8k+Vg4fPuwkuebmZufc6f/348aNc5s3b47c5p///KeT5FpaWqzWTLgvnwfnnPvmN7/p7r//frulvoJR/wzo5MmT2rt3r8rLyyOXpaenq7y8XC0tLYab2Thw4IAKCws1depU3X333erq6rJeyVRnZ6d6enqiHh9+v1+lpaUX5eOjqalJeXl5mj59uu677z4dOXLEeqWECoVCkqScnBxJ0t69e3Xq1Kmox8OMGTM0ZcqUlH48fPk8fO6ll15Sbm6uZs6cqdraWh0/ftxivbMadW9G+mWffPKJBgcHlZ+fH3V5fn6+PvzwQ6OtbJSWlqqhoUHTp09Xd3e31q1bpxtvvFH79+9XZmam9Xomenp6JGnYx8fn110sKisrddttt6mkpEQdHR36xS9+oaqqKrW0tGjMmDHW68Xd0NCQ1qxZowULFmjmzJmSTj8eMjIylJ2dHXXbVH48DHceJOmuu+5ScXGxCgsL1draqocfflhtbW167bXXDLeNNuoDhP9XVVUV+fPs2bNVWlqq4uJi/fnPf9Y999xjuBlGgzvuuCPy51mzZmn27NmaNm2ampqatGjRIsPNEiMYDGr//v0XxfdBz+Vs52HlypWRP8+aNUsFBQVatGiROjo6NG3atJFec1ij/ktwubm5GjNmzBmvYunt7VUgEDDaanTIzs7W1Vdfrfb2dutVzHz+GODxcaapU6cqNzc3JR8fq1at0htvvKF33nkn6te3BAIBnTx5UkePHo26fao+Hs52HoZTWloqSaPq8TDqA5SRkaG5c+eqsbExctnQ0JAaGxtVVlZmuJm9Y8eOqaOjQwUFBdarmCkpKVEgEIh6fITDYe3evfuif3x8/PHHOnLkSEo9PpxzWrVqlbZs2aK3335bJSUlUdfPnTtX48aNi3o8tLW1qaurK6UeD+c7D8PZt2+fJI2ux4P1qyC+ildeecX5fD7X0NDg/vGPf7iVK1e67Oxs19PTY73aiPrZz37mmpqaXGdnp/vb3/7mysvLXW5urjt8+LD1agnV19fnPvjgA/fBBx84Se6pp55yH3zwgfvoo4+cc8795je/cdnZ2W7btm2utbXV3XLLLa6kpMR9+umnxpvH17nOQ19fn3vwwQddS0uL6+zsdG+99Za77rrr3FVXXeVOnDhhvXrc3Hfffc7v97umpibX3d0dOY4fPx65zb333uumTJni3n77bbdnzx5XVlbmysrKDLeOv/Odh/b2dvfEE0+4PXv2uM7OTrdt2zY3depUt3DhQuPNoyVFgJxz7ne/+52bMmWKy8jIcPPnz3e7du2yXmnE3X777a6goMBlZGS4yy+/3N1+++2uvb3deq2Ee+edd5ykM47q6mrn3OmXYj/66KMuPz/f+Xw+t2jRItfW1ma7dAKc6zwcP37cLV682E2aNMmNGzfOFRcXuxUrVqTcP9KG+++X5DZu3Bi5zaeffup+8pOfuK997Wvukksucbfeeqvr7u62WzoBznceurq63MKFC11OTo7z+XzuyiuvdD//+c9dKBSyXfxL+HUMAAATo/57QACA1ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPg/CTLAosPN138AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "data, target = test_data[0]  # Get the first test data sample and its target\n",
    "\n",
    "data = data.unsqueeze(0).to(device)  # Add a batch dimension and move data to the device (GPU or CPU)\n",
    "\n",
    "output = model(data)  # Pass the data through the model to get the output predictions\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()  # Get the predicted class\n",
    "\n",
    "print(f'Prediction: {prediction}')  # Print the predicted class\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()  # Remove the batch and channel dimensions, move to CPU, and convert to numpy array\n",
    "\n",
    "plt.imshow(image, cmap='gray')  # Display the image in grayscale\n",
    "\n",
    "plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0720c6-7043-4332-9bea-8f5d745d7b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
