{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486dd478-f8c8-42a3-879c-ab39b8392b5b",
   "metadata": {},
   "source": [
    "# Image Classification using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dbea37e-0026-4e3b-937a-909a70556395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install: pip3 install torch torchvision matplotlib\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor # turn image data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b10d093-8500-45b4-9d73-dc6f798f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
    "test_data = datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17677e3-74c1-4991-b3bb-f6e30743969a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefe7420-af61-4503-a9ee-c4411d47a5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb81af5-f15c-4f11-8f2c-f809d3e07805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data # gives you data with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08851a70-9c0e-4a6f-b297-ec39a38ad3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape # grayscale in one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731b068c-4a95-4fef-ba02-b826a87c10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size() # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac136d7-56e9-4b9e-8794-7ee35a2f9767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeead1d3-b2a4-4ffa-b9d6-562715f99fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a6b7bb-b5f5-4b3a-bb82-b7bf18af3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b831991-fc8d-4fdb-b397-d7154c8541c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size = 100, shuffle=True, num_workers=1),\n",
    "    'test': DataLoader(test_data, batch_size = 100, shuffle=True, num_workers=1),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd465c37-d915-4329-82c9-34175645cbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1a886acf500>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1a886a73dd0>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3443e1f-dd2a-401f-9c41-4682c8a6878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim # optimizer\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=5) # 1 channel in, 10 channel out\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d() # dropout regularization layer based on probability where some nodes are deactivated\n",
    "        # fully connected layers\n",
    "        self.fc1 = nn.Linear(320, 50) # dense layer\n",
    "        self.fc2 = nn.Linear(50, 10) \n",
    "\n",
    "    # defines the forward pass of the network, which is how the input data x is processed through the layers of the network\n",
    "    def forward(self, x): \n",
    "        # ReLU - rectified linear unit activation function for model linearity\n",
    "        # F.relu(...): Applies the ReLU activation function to the output\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) \n",
    "        # F.max_pool2d(..., 2): Applies a 2D max pooling operation with a kernel size of 2\n",
    "        x = x.view(-1, 320) # 320 = 20 x 4 x 4: reshape x to have 320 features\n",
    "        x = F.relu(self.fc1(x)) # Apply a fully connected layer and ReLU activation\n",
    "        x = F.dropout(x, training=self.training) # Apply dropout to prevent overfitting.\n",
    "        x = self.fc2(x) # Apply another fully connected layer.\n",
    "        # Convert the output to probabilities.\n",
    "        return F.softmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ec239-bbf0-48e3-88ef-ade2a0b355bb",
   "metadata": {},
   "source": [
    "### Fully Connected Layer: This layer connects every neuron in the previous layer to every neuron in the next layer.\n",
    "### ReLU Activation: Introduces non-linearity to the model and helps the neural network learn more complex functions and improves its ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d1b707b-ffe6-4e06-9e22-4eb3f95c6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The Adam optimizer is a popular optimization algorithm used in training deep learning models. It stands for Adaptive Moment Estimation.\n",
    "###### Uses moving averages of the gradients and the squared gradients to provide a smoother and more stable update process.\n",
    "###### Adjusts the learning rate for each parameter individually, which helps in faster convergence and better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eec4ead-4b01-42e4-ad41-e255d21d3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following process needs to be done manually in Torch; not in Keras\n",
    "import torch\n",
    "\n",
    "# optimize the performance of neural network training and inference\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Creates an instance of the CNN model and moves it to the specified device (GPU or CPU)\n",
    "model = CNN().to(device)\n",
    "# Initializes the Adam optimizer with the model's parameters and a learning rate of 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Defines the loss function as cross-entropy loss, commonly used for classification tasks.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch): \n",
    "    model.train() # put model in training mode\n",
    "    for batch_index, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad() # set the gradient of each batch to zero \n",
    "        output = model(data) # Passes the input data through the model to get the output predictions.\n",
    "        loss = loss_fn(output, target) # Calculates the loss between the model's predictions and the actual target values. \n",
    "        loss.backward() # Computes the gradients of the loss with respect to the model's parameters (weights) for backpropagation.\n",
    "        optimizer.step() # Updates the model's parameters using the computed gradients to minimize the loss.\n",
    "\n",
    "        '''\n",
    "        # Checks if batch_index is a multiple of 20. \n",
    "        # If it is, it prints the current training epoch, the progress of the batches processed, and the current loss value.\n",
    "        if batch_index % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(loaders[\"train\"].dataset)}'\n",
    "      f' ({100. * batch_index / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}') '''\n",
    "\n",
    "        # Every 20 batches, print the training progress\n",
    "        if batch_index % 20 == 0:\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_index}, Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e458194-e495-49f0-bb9f-688f9e732b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            # finds the index of the maximum value in the output tensor along the specified dimension\n",
    "            prediction = output.argmax(dim=1, keepdim=True) # ensures that the output tensor retains the same number of dimensions as the input\n",
    "            # compares the predicted classes with the actual target and counts the number of correct predictions and adds this count to the cumulative\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    average_loss = test_loss\n",
    "    total_samples = len(loaders['test'].dataset)\n",
    "    accuracy = 100. * correct / total_samples\n",
    "    \n",
    "    print(f'Test Set: Average Loss: {average_loss:.4f}, Accuracy: {correct}/{total_samples} ({accuracy:.0f}%)')                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc560d54-a0ea-4b59-8660-365bac8c248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Batch normalization is a technique used in training deep neural networks to improve their performance and stability.\n",
    "###### It normalizes the input of each layer so that they have a mean of 0 and a standard deviation of 1. \n",
    "###### This helps in stabilizing the learning process. After normalization, it scales and shifts the data using learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9632f3b-3b17-403c-bd0c-a9dd559a7039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\646ca\\AppData\\Local\\Temp\\ipykernel_27608\\761587904.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 1.538422\n",
      "Epoch: 1, Batch: 20, Loss: 1.651673\n",
      "Epoch: 1, Batch: 40, Loss: 1.582036\n",
      "Epoch: 1, Batch: 60, Loss: 1.578352\n",
      "Epoch: 1, Batch: 80, Loss: 1.561228\n",
      "Epoch: 1, Batch: 100, Loss: 1.612728\n",
      "Epoch: 1, Batch: 120, Loss: 1.625250\n",
      "Epoch: 1, Batch: 140, Loss: 1.586293\n",
      "Epoch: 1, Batch: 160, Loss: 1.597601\n",
      "Epoch: 1, Batch: 180, Loss: 1.553201\n",
      "Epoch: 1, Batch: 200, Loss: 1.560512\n",
      "Epoch: 1, Batch: 220, Loss: 1.616825\n",
      "Epoch: 1, Batch: 240, Loss: 1.594082\n",
      "Epoch: 1, Batch: 260, Loss: 1.571241\n",
      "Epoch: 1, Batch: 280, Loss: 1.567431\n",
      "Epoch: 1, Batch: 300, Loss: 1.576642\n",
      "Epoch: 1, Batch: 320, Loss: 1.550215\n",
      "Epoch: 1, Batch: 340, Loss: 1.569501\n",
      "Epoch: 1, Batch: 360, Loss: 1.595542\n",
      "Epoch: 1, Batch: 380, Loss: 1.591128\n",
      "Epoch: 1, Batch: 400, Loss: 1.588434\n",
      "Epoch: 1, Batch: 420, Loss: 1.574360\n",
      "Epoch: 1, Batch: 440, Loss: 1.562705\n",
      "Epoch: 1, Batch: 460, Loss: 1.563896\n",
      "Epoch: 1, Batch: 480, Loss: 1.590219\n",
      "Epoch: 1, Batch: 500, Loss: 1.557410\n",
      "Epoch: 1, Batch: 520, Loss: 1.600300\n",
      "Epoch: 1, Batch: 540, Loss: 1.581901\n",
      "Epoch: 1, Batch: 560, Loss: 1.557459\n",
      "Epoch: 1, Batch: 580, Loss: 1.547261\n",
      "Test Set: Average Loss: 0.0151, Accuracy: 9561/10000 (96%)\n",
      "Epoch: 2, Batch: 0, Loss: 1.537018\n",
      "Epoch: 2, Batch: 20, Loss: 1.592253\n",
      "Epoch: 2, Batch: 40, Loss: 1.556202\n",
      "Epoch: 2, Batch: 60, Loss: 1.615089\n",
      "Epoch: 2, Batch: 80, Loss: 1.531403\n",
      "Epoch: 2, Batch: 100, Loss: 1.575711\n",
      "Epoch: 2, Batch: 120, Loss: 1.549675\n",
      "Epoch: 2, Batch: 140, Loss: 1.553179\n",
      "Epoch: 2, Batch: 160, Loss: 1.566883\n",
      "Epoch: 2, Batch: 180, Loss: 1.551759\n",
      "Epoch: 2, Batch: 200, Loss: 1.511981\n",
      "Epoch: 2, Batch: 220, Loss: 1.567190\n",
      "Epoch: 2, Batch: 240, Loss: 1.570736\n",
      "Epoch: 2, Batch: 260, Loss: 1.534340\n",
      "Epoch: 2, Batch: 280, Loss: 1.537889\n",
      "Epoch: 2, Batch: 300, Loss: 1.531100\n",
      "Epoch: 2, Batch: 320, Loss: 1.545790\n",
      "Epoch: 2, Batch: 340, Loss: 1.614709\n",
      "Epoch: 2, Batch: 360, Loss: 1.503414\n",
      "Epoch: 2, Batch: 380, Loss: 1.600348\n",
      "Epoch: 2, Batch: 400, Loss: 1.510340\n",
      "Epoch: 2, Batch: 420, Loss: 1.546726\n",
      "Epoch: 2, Batch: 440, Loss: 1.552855\n",
      "Epoch: 2, Batch: 460, Loss: 1.566099\n",
      "Epoch: 2, Batch: 480, Loss: 1.580612\n",
      "Epoch: 2, Batch: 500, Loss: 1.564836\n",
      "Epoch: 2, Batch: 520, Loss: 1.621487\n",
      "Epoch: 2, Batch: 540, Loss: 1.587612\n",
      "Epoch: 2, Batch: 560, Loss: 1.563437\n",
      "Epoch: 2, Batch: 580, Loss: 1.536096\n",
      "Test Set: Average Loss: 0.0150, Accuracy: 9611/10000 (96%)\n",
      "Epoch: 3, Batch: 0, Loss: 1.531281\n",
      "Epoch: 3, Batch: 20, Loss: 1.527494\n",
      "Epoch: 3, Batch: 40, Loss: 1.516913\n",
      "Epoch: 3, Batch: 60, Loss: 1.531242\n",
      "Epoch: 3, Batch: 80, Loss: 1.533877\n",
      "Epoch: 3, Batch: 100, Loss: 1.537199\n",
      "Epoch: 3, Batch: 120, Loss: 1.532907\n",
      "Epoch: 3, Batch: 140, Loss: 1.578242\n",
      "Epoch: 3, Batch: 160, Loss: 1.551237\n",
      "Epoch: 3, Batch: 180, Loss: 1.604211\n",
      "Epoch: 3, Batch: 200, Loss: 1.556251\n",
      "Epoch: 3, Batch: 220, Loss: 1.513452\n",
      "Epoch: 3, Batch: 240, Loss: 1.577795\n",
      "Epoch: 3, Batch: 260, Loss: 1.555166\n",
      "Epoch: 3, Batch: 280, Loss: 1.540228\n",
      "Epoch: 3, Batch: 300, Loss: 1.555218\n",
      "Epoch: 3, Batch: 320, Loss: 1.530495\n",
      "Epoch: 3, Batch: 340, Loss: 1.559480\n",
      "Epoch: 3, Batch: 360, Loss: 1.559483\n",
      "Epoch: 3, Batch: 380, Loss: 1.542856\n",
      "Epoch: 3, Batch: 400, Loss: 1.609359\n",
      "Epoch: 3, Batch: 420, Loss: 1.543212\n",
      "Epoch: 3, Batch: 440, Loss: 1.568294\n",
      "Epoch: 3, Batch: 460, Loss: 1.570810\n",
      "Epoch: 3, Batch: 480, Loss: 1.531491\n",
      "Epoch: 3, Batch: 500, Loss: 1.500456\n",
      "Epoch: 3, Batch: 520, Loss: 1.532430\n",
      "Epoch: 3, Batch: 540, Loss: 1.526426\n",
      "Epoch: 3, Batch: 560, Loss: 1.595548\n",
      "Epoch: 3, Batch: 580, Loss: 1.506423\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9675/10000 (97%)\n",
      "Epoch: 4, Batch: 0, Loss: 1.537339\n",
      "Epoch: 4, Batch: 20, Loss: 1.487915\n",
      "Epoch: 4, Batch: 40, Loss: 1.510411\n",
      "Epoch: 4, Batch: 60, Loss: 1.575467\n",
      "Epoch: 4, Batch: 80, Loss: 1.502836\n",
      "Epoch: 4, Batch: 100, Loss: 1.530702\n",
      "Epoch: 4, Batch: 120, Loss: 1.531199\n",
      "Epoch: 4, Batch: 140, Loss: 1.585400\n",
      "Epoch: 4, Batch: 160, Loss: 1.500208\n",
      "Epoch: 4, Batch: 180, Loss: 1.496286\n",
      "Epoch: 4, Batch: 200, Loss: 1.586198\n",
      "Epoch: 4, Batch: 220, Loss: 1.544562\n",
      "Epoch: 4, Batch: 240, Loss: 1.535344\n",
      "Epoch: 4, Batch: 260, Loss: 1.574190\n",
      "Epoch: 4, Batch: 280, Loss: 1.543963\n",
      "Epoch: 4, Batch: 300, Loss: 1.502932\n",
      "Epoch: 4, Batch: 320, Loss: 1.539876\n",
      "Epoch: 4, Batch: 340, Loss: 1.534808\n",
      "Epoch: 4, Batch: 360, Loss: 1.508206\n",
      "Epoch: 4, Batch: 380, Loss: 1.517316\n",
      "Epoch: 4, Batch: 400, Loss: 1.530942\n",
      "Epoch: 4, Batch: 420, Loss: 1.522739\n",
      "Epoch: 4, Batch: 440, Loss: 1.537587\n",
      "Epoch: 4, Batch: 460, Loss: 1.510868\n",
      "Epoch: 4, Batch: 480, Loss: 1.521472\n",
      "Epoch: 4, Batch: 500, Loss: 1.553837\n",
      "Epoch: 4, Batch: 520, Loss: 1.566594\n",
      "Epoch: 4, Batch: 540, Loss: 1.549143\n",
      "Epoch: 4, Batch: 560, Loss: 1.545599\n",
      "Epoch: 4, Batch: 580, Loss: 1.528275\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9686/10000 (97%)\n",
      "Epoch: 5, Batch: 0, Loss: 1.566314\n",
      "Epoch: 5, Batch: 20, Loss: 1.544072\n",
      "Epoch: 5, Batch: 40, Loss: 1.513544\n",
      "Epoch: 5, Batch: 60, Loss: 1.510066\n",
      "Epoch: 5, Batch: 80, Loss: 1.540902\n",
      "Epoch: 5, Batch: 100, Loss: 1.502635\n",
      "Epoch: 5, Batch: 120, Loss: 1.504374\n",
      "Epoch: 5, Batch: 140, Loss: 1.556297\n",
      "Epoch: 5, Batch: 160, Loss: 1.532868\n",
      "Epoch: 5, Batch: 180, Loss: 1.537111\n",
      "Epoch: 5, Batch: 200, Loss: 1.566270\n",
      "Epoch: 5, Batch: 220, Loss: 1.534182\n",
      "Epoch: 5, Batch: 240, Loss: 1.533375\n",
      "Epoch: 5, Batch: 260, Loss: 1.519750\n",
      "Epoch: 5, Batch: 280, Loss: 1.530864\n",
      "Epoch: 5, Batch: 300, Loss: 1.531662\n",
      "Epoch: 5, Batch: 320, Loss: 1.520555\n",
      "Epoch: 5, Batch: 340, Loss: 1.546263\n",
      "Epoch: 5, Batch: 360, Loss: 1.543065\n",
      "Epoch: 5, Batch: 380, Loss: 1.538056\n",
      "Epoch: 5, Batch: 400, Loss: 1.567292\n",
      "Epoch: 5, Batch: 420, Loss: 1.542150\n",
      "Epoch: 5, Batch: 440, Loss: 1.522592\n",
      "Epoch: 5, Batch: 460, Loss: 1.506420\n",
      "Epoch: 5, Batch: 480, Loss: 1.541352\n",
      "Epoch: 5, Batch: 500, Loss: 1.525828\n",
      "Epoch: 5, Batch: 520, Loss: 1.527276\n",
      "Epoch: 5, Batch: 540, Loss: 1.573418\n",
      "Epoch: 5, Batch: 560, Loss: 1.557370\n",
      "Epoch: 5, Batch: 580, Loss: 1.527982\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9726/10000 (97%)\n",
      "Epoch: 6, Batch: 0, Loss: 1.516107\n",
      "Epoch: 6, Batch: 20, Loss: 1.512046\n",
      "Epoch: 6, Batch: 40, Loss: 1.532153\n",
      "Epoch: 6, Batch: 60, Loss: 1.491656\n",
      "Epoch: 6, Batch: 80, Loss: 1.494585\n",
      "Epoch: 6, Batch: 100, Loss: 1.585328\n",
      "Epoch: 6, Batch: 120, Loss: 1.526238\n",
      "Epoch: 6, Batch: 140, Loss: 1.573680\n",
      "Epoch: 6, Batch: 160, Loss: 1.540781\n",
      "Epoch: 6, Batch: 180, Loss: 1.544618\n",
      "Epoch: 6, Batch: 200, Loss: 1.545897\n",
      "Epoch: 6, Batch: 220, Loss: 1.510990\n",
      "Epoch: 6, Batch: 240, Loss: 1.512346\n",
      "Epoch: 6, Batch: 260, Loss: 1.562397\n",
      "Epoch: 6, Batch: 280, Loss: 1.512366\n",
      "Epoch: 6, Batch: 300, Loss: 1.542984\n",
      "Epoch: 6, Batch: 320, Loss: 1.526473\n",
      "Epoch: 6, Batch: 340, Loss: 1.545675\n",
      "Epoch: 6, Batch: 360, Loss: 1.540081\n",
      "Epoch: 6, Batch: 380, Loss: 1.518140\n",
      "Epoch: 6, Batch: 400, Loss: 1.560694\n",
      "Epoch: 6, Batch: 420, Loss: 1.537143\n",
      "Epoch: 6, Batch: 440, Loss: 1.537114\n",
      "Epoch: 6, Batch: 460, Loss: 1.499394\n",
      "Epoch: 6, Batch: 480, Loss: 1.528385\n",
      "Epoch: 6, Batch: 500, Loss: 1.536970\n",
      "Epoch: 6, Batch: 520, Loss: 1.539840\n",
      "Epoch: 6, Batch: 540, Loss: 1.525057\n",
      "Epoch: 6, Batch: 560, Loss: 1.536858\n",
      "Epoch: 6, Batch: 580, Loss: 1.486010\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9723/10000 (97%)\n",
      "Epoch: 7, Batch: 0, Loss: 1.534691\n",
      "Epoch: 7, Batch: 20, Loss: 1.535354\n",
      "Epoch: 7, Batch: 40, Loss: 1.530902\n",
      "Epoch: 7, Batch: 60, Loss: 1.541814\n",
      "Epoch: 7, Batch: 80, Loss: 1.552913\n",
      "Epoch: 7, Batch: 100, Loss: 1.518098\n",
      "Epoch: 7, Batch: 120, Loss: 1.542767\n",
      "Epoch: 7, Batch: 140, Loss: 1.491665\n",
      "Epoch: 7, Batch: 160, Loss: 1.539937\n",
      "Epoch: 7, Batch: 180, Loss: 1.551375\n",
      "Epoch: 7, Batch: 200, Loss: 1.507858\n",
      "Epoch: 7, Batch: 220, Loss: 1.548491\n",
      "Epoch: 7, Batch: 240, Loss: 1.533226\n",
      "Epoch: 7, Batch: 260, Loss: 1.512616\n",
      "Epoch: 7, Batch: 280, Loss: 1.598520\n",
      "Epoch: 7, Batch: 300, Loss: 1.515258\n",
      "Epoch: 7, Batch: 320, Loss: 1.528964\n",
      "Epoch: 7, Batch: 340, Loss: 1.525473\n",
      "Epoch: 7, Batch: 360, Loss: 1.576425\n",
      "Epoch: 7, Batch: 380, Loss: 1.573512\n",
      "Epoch: 7, Batch: 400, Loss: 1.500517\n",
      "Epoch: 7, Batch: 420, Loss: 1.528519\n",
      "Epoch: 7, Batch: 440, Loss: 1.561787\n",
      "Epoch: 7, Batch: 460, Loss: 1.505623\n",
      "Epoch: 7, Batch: 480, Loss: 1.496196\n",
      "Epoch: 7, Batch: 500, Loss: 1.516073\n",
      "Epoch: 7, Batch: 520, Loss: 1.541976\n",
      "Epoch: 7, Batch: 540, Loss: 1.583337\n",
      "Epoch: 7, Batch: 560, Loss: 1.555251\n",
      "Epoch: 7, Batch: 580, Loss: 1.514787\n",
      "Test Set: Average Loss: 0.0149, Accuracy: 9755/10000 (98%)\n",
      "Epoch: 8, Batch: 0, Loss: 1.521145\n",
      "Epoch: 8, Batch: 20, Loss: 1.550801\n",
      "Epoch: 8, Batch: 40, Loss: 1.556258\n",
      "Epoch: 8, Batch: 60, Loss: 1.530210\n",
      "Epoch: 8, Batch: 80, Loss: 1.536746\n",
      "Epoch: 8, Batch: 100, Loss: 1.541605\n",
      "Epoch: 8, Batch: 120, Loss: 1.531674\n",
      "Epoch: 8, Batch: 140, Loss: 1.490819\n",
      "Epoch: 8, Batch: 160, Loss: 1.511417\n",
      "Epoch: 8, Batch: 180, Loss: 1.551744\n",
      "Epoch: 8, Batch: 200, Loss: 1.504385\n",
      "Epoch: 8, Batch: 220, Loss: 1.552173\n",
      "Epoch: 8, Batch: 240, Loss: 1.510651\n",
      "Epoch: 8, Batch: 260, Loss: 1.502799\n",
      "Epoch: 8, Batch: 280, Loss: 1.473611\n",
      "Epoch: 8, Batch: 300, Loss: 1.496176\n",
      "Epoch: 8, Batch: 320, Loss: 1.499795\n",
      "Epoch: 8, Batch: 340, Loss: 1.538209\n",
      "Epoch: 8, Batch: 360, Loss: 1.498171\n",
      "Epoch: 8, Batch: 380, Loss: 1.518145\n",
      "Epoch: 8, Batch: 400, Loss: 1.528705\n",
      "Epoch: 8, Batch: 420, Loss: 1.536570\n",
      "Epoch: 8, Batch: 440, Loss: 1.481749\n",
      "Epoch: 8, Batch: 460, Loss: 1.483907\n",
      "Epoch: 8, Batch: 480, Loss: 1.557622\n",
      "Epoch: 8, Batch: 500, Loss: 1.515751\n",
      "Epoch: 8, Batch: 520, Loss: 1.496797\n",
      "Epoch: 8, Batch: 540, Loss: 1.520459\n",
      "Epoch: 8, Batch: 560, Loss: 1.517279\n",
      "Epoch: 8, Batch: 580, Loss: 1.498428\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9766/10000 (98%)\n",
      "Epoch: 9, Batch: 0, Loss: 1.513895\n",
      "Epoch: 9, Batch: 20, Loss: 1.535899\n",
      "Epoch: 9, Batch: 40, Loss: 1.504759\n",
      "Epoch: 9, Batch: 60, Loss: 1.514251\n",
      "Epoch: 9, Batch: 80, Loss: 1.556486\n",
      "Epoch: 9, Batch: 100, Loss: 1.516883\n",
      "Epoch: 9, Batch: 120, Loss: 1.518066\n",
      "Epoch: 9, Batch: 140, Loss: 1.530151\n",
      "Epoch: 9, Batch: 160, Loss: 1.568478\n",
      "Epoch: 9, Batch: 180, Loss: 1.499848\n",
      "Epoch: 9, Batch: 200, Loss: 1.521902\n",
      "Epoch: 9, Batch: 220, Loss: 1.511707\n",
      "Epoch: 9, Batch: 240, Loss: 1.518670\n",
      "Epoch: 9, Batch: 260, Loss: 1.511275\n",
      "Epoch: 9, Batch: 280, Loss: 1.477268\n",
      "Epoch: 9, Batch: 300, Loss: 1.512548\n",
      "Epoch: 9, Batch: 320, Loss: 1.530300\n",
      "Epoch: 9, Batch: 340, Loss: 1.493286\n",
      "Epoch: 9, Batch: 360, Loss: 1.525769\n",
      "Epoch: 9, Batch: 380, Loss: 1.514020\n",
      "Epoch: 9, Batch: 400, Loss: 1.528813\n",
      "Epoch: 9, Batch: 420, Loss: 1.520106\n",
      "Epoch: 9, Batch: 440, Loss: 1.502078\n",
      "Epoch: 9, Batch: 460, Loss: 1.493749\n",
      "Epoch: 9, Batch: 480, Loss: 1.520767\n",
      "Epoch: 9, Batch: 500, Loss: 1.534227\n",
      "Epoch: 9, Batch: 520, Loss: 1.505251\n",
      "Epoch: 9, Batch: 540, Loss: 1.506403\n",
      "Epoch: 9, Batch: 560, Loss: 1.511995\n",
      "Epoch: 9, Batch: 580, Loss: 1.522315\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9786/10000 (98%)\n",
      "Epoch: 10, Batch: 0, Loss: 1.520294\n",
      "Epoch: 10, Batch: 20, Loss: 1.535609\n",
      "Epoch: 10, Batch: 40, Loss: 1.578003\n",
      "Epoch: 10, Batch: 60, Loss: 1.525899\n",
      "Epoch: 10, Batch: 80, Loss: 1.542132\n",
      "Epoch: 10, Batch: 100, Loss: 1.522812\n",
      "Epoch: 10, Batch: 120, Loss: 1.483241\n",
      "Epoch: 10, Batch: 140, Loss: 1.482114\n",
      "Epoch: 10, Batch: 160, Loss: 1.498142\n",
      "Epoch: 10, Batch: 180, Loss: 1.516700\n",
      "Epoch: 10, Batch: 200, Loss: 1.467350\n",
      "Epoch: 10, Batch: 220, Loss: 1.552074\n",
      "Epoch: 10, Batch: 240, Loss: 1.505124\n",
      "Epoch: 10, Batch: 260, Loss: 1.524279\n",
      "Epoch: 10, Batch: 280, Loss: 1.489388\n",
      "Epoch: 10, Batch: 300, Loss: 1.497856\n",
      "Epoch: 10, Batch: 320, Loss: 1.521119\n",
      "Epoch: 10, Batch: 340, Loss: 1.517149\n",
      "Epoch: 10, Batch: 360, Loss: 1.490116\n",
      "Epoch: 10, Batch: 380, Loss: 1.500478\n",
      "Epoch: 10, Batch: 400, Loss: 1.511039\n",
      "Epoch: 10, Batch: 420, Loss: 1.508639\n",
      "Epoch: 10, Batch: 440, Loss: 1.551419\n",
      "Epoch: 10, Batch: 460, Loss: 1.537385\n",
      "Epoch: 10, Batch: 480, Loss: 1.490597\n",
      "Epoch: 10, Batch: 500, Loss: 1.483326\n",
      "Epoch: 10, Batch: 520, Loss: 1.523650\n",
      "Epoch: 10, Batch: 540, Loss: 1.522485\n",
      "Epoch: 10, Batch: 560, Loss: 1.489439\n",
      "Epoch: 10, Batch: 580, Loss: 1.502292\n",
      "Test Set: Average Loss: 0.0148, Accuracy: 9798/10000 (98%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11): \n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8991b453-c796-40da-9783-051756696151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5e2d9b4-2f0f-449c-8186-a8662fe5f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8edd46f8-0f8c-4ab7-9f29-4e771c95bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\646ca\\AppData\\Local\\Temp\\ipykernel_27608\\761587904.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "data, target = test_data[0]  # Get the first test data sample and its target\n",
    "\n",
    "data = data.unsqueeze(0).to(device)  # Add a batch dimension and move data to the device (GPU or CPU)\n",
    "\n",
    "output = model(data)  # Pass the data through the model to get the output predictions\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()  # Get the predicted class\n",
    "\n",
    "print(f'Prediction: {prediction}')  # Print the predicted class\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()  # Remove the batch and channel dimensions, move to CPU, and convert to numpy array\n",
    "\n",
    "plt.imshow(image, cmap='gray')  # Display the image in grayscale\n",
    "\n",
    "plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0720c6-7043-4332-9bea-8f5d745d7b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
